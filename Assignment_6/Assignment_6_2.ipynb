{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc54440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23db755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.InceptionResNetV2(include_top=True, weights='imagenet')\n",
    "model.trainable = False\n",
    "\n",
    "# ImageNet labels\n",
    "decode_predictions = tf.keras.applications.inception_resnet_v2.decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cca8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to preprocess the image so that it can be inputted in MobileNetV2\n",
    "def preprocess(image):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = tf.image.resize(image, (299, 299))\n",
    "  image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "  image = image[None, ...]\n",
    "  return image\n",
    "\n",
    "# Helper function to extract labels from probability vector\n",
    "def get_imagenet_label(probs):\n",
    "  return decode_predictions(probs, top=1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc84b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./plane.jpeg\"\n",
    "image_raw = tf.io.read_file(image_path)\n",
    "image = tf.image.decode_image(image_raw)\n",
    "\n",
    "image = preprocess(image)\n",
    "image_probs = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc31968",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(image[0] * 0.5 + 0.5)\n",
    "_, image_class, class_confidance = get_imagenet_label(image_probs)\n",
    "plt.title('{} : {:.2f}% Confidance'.format(image_class, class_confidance*100))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a155cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "def create_adversarial_pattern(input_image, input_label):\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(input_image)\n",
    "    prediction = model(input_image)\n",
    "    loss = loss_object(input_label, prediction)\n",
    "\n",
    "  # Get the gradients of the loss w.r.t to the input image.\n",
    "  gradient = tape.gradient(loss, input_image)\n",
    "  # Get the sign of the gradients to create the perturbation\n",
    "  signed_grad = tf.sign(gradient)\n",
    "  return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b13f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input label of the image.\n",
    "labrador_retriever_index = 41\n",
    "label = tf.one_hot(labrador_retriever_index, image_probs.shape[-1])\n",
    "label = tf.reshape(label, (1, image_probs.shape[-1]))\n",
    "\n",
    "perturbations = create_adversarial_pattern(image, label)\n",
    "plt.imshow(perturbations[0] * 0.5 + 0.5);  # To change [-1, 1] to [0,1]\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e8fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = .2\n",
    "description = f\"Epsilon = {epsilon:.2f}\"\n",
    "\n",
    "# Generate adversarial image\n",
    "adv_x = image + epsilon * perturbations\n",
    "adv_x = tf.clip_by_value(adv_x, -1, 1)\n",
    "\n",
    "# Predict label\n",
    "pred = model(adv_x)\n",
    "label = get_imagenet_label(pred)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(adv_x[0] * 0.5 + 0.5)  # Convert from [-1, 1] to [0, 1] for display\n",
    "plt.title(f\"{description}\\nPred: {label[1]} | Confidence: {label[2]*100:.2f}%\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ce3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(image[0] * 0.5 + 0.5) # To change [-1, 1] to [0,1]\n",
    "_, image_class, class_confidance = get_imagenet_label(image_probs)\n",
    "plt.title('Original\\n{} : {:.2f}% Confidance'.format(image_class, class_confidance*100))\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(perturbations[0] * 0.5 + 0.5)\n",
    "_, image_class, class_confidance = get_imagenet_label(model.predict(perturbations))\n",
    "plt.title('Perturabation\\n{} : {:.2f}% Confidance'.format(image_class, class_confidance*100))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(adv_x[0] * 0.5 + 0.5)\n",
    "_, image_class, class_confidance = get_imagenet_label(model.predict(adv_x))\n",
    "plt.title('Adversary (epsilon = 0.2)\\n{} : {:.2f}% Confidance'.format(image_class, class_confidance*100))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b3eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_x.shape, adv_x.dtype, image.shape, image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8905d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = keras.models.Model(model.inputs, [model.get_layer(last_conv_layer_name).output, model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0228986",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = make_gradcam_heatmap(img_array=adv_x, model=model, last_conv_layer_name='conv_7b', pred_index=48)\n",
    "# Display heatmap\n",
    "plt.matshow(heatmap)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4842fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_display_gradcam(img_tensor, heatmap, alpha=0.4):\n",
    "    img = img_tensor[0].numpy()                 # shape: (224, 224, 3), range [-1, 1]\n",
    "    img = (img + 1.0) / 2.0                      # scale to [0, 1]\n",
    "    img = np.uint8(255 * img)                   # scale to [0, 255]\n",
    "\n",
    "    # Rescale heatmap to [0, 255]\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap\n",
    "    jet = mpl.colormaps[\"jet\"]\n",
    "    jet_colors = jet(np.arange(256))[:, :3]     # shape: (256, 3)\n",
    "    jet_heatmap = jet_colors[heatmap]           # shape: (H, W, 3), still float32 in [0, 1]\n",
    "\n",
    "    # Resize heatmap directly using PIL (more accurate resizing)\n",
    "    heatmap_img = Image.fromarray(np.uint8(jet_heatmap * 255))\n",
    "    heatmap_img = heatmap_img.resize((img.shape[1], img.shape[0]), resample=Image.BILINEAR)\n",
    "    jet_heatmap = np.array(heatmap_img)         # shape: (H, W, 3), dtype: uint8\n",
    "\n",
    "    # Superimpose\n",
    "    superimposed_img = jet_heatmap * alpha + img * (1 - alpha)\n",
    "    superimposed_img = np.uint8(superimposed_img)\n",
    "\n",
    "    return superimposed_img\n",
    "    # plt.matshow(superimposed_img)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b67850",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43826a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_original = make_gradcam_heatmap(img_array=image, model=model, last_conv_layer_name='conv_7b', pred_index=41)\n",
    "# Display heatmap\n",
    "plt.matshow(heatmap)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccec8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_and_display_gradcam(image, heatmap=heatmap_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b07d4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_images(baseline,\n",
    "                       image,\n",
    "                       alphas):\n",
    "  alphas_x = alphas[:, tf.newaxis, tf.newaxis, tf.newaxis]\n",
    "  baseline_x = tf.expand_dims(baseline, axis=0)\n",
    "  input_x = tf.expand_dims(image, axis=0)\n",
    "  delta = input_x - baseline_x\n",
    "  images = baseline_x +  alphas_x * delta\n",
    "  return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integral_approximation(gradients):\n",
    "  # riemann_trapezoidal\n",
    "  grads = (gradients[:-1] + gradients[1:]) / tf.constant(2.0)\n",
    "  integrated_gradients = tf.math.reduce_mean(grads, axis=0)\n",
    "  return integrated_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06df0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(images, target_class_idx):\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(images)\n",
    "    logits = model(images)\n",
    "    probs = tf.nn.softmax(logits, axis=-1)[:, target_class_idx]\n",
    "  return tape.gradient(probs, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea83b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrated_gradients(baseline,\n",
    "                         image,\n",
    "                         target_class_idx,\n",
    "                         m_steps=50,\n",
    "                         batch_size=32):\n",
    "  # Generate alphas.\n",
    "  alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps+1)\n",
    "\n",
    "  # Collect gradients.    \n",
    "  gradient_batches = []\n",
    "\n",
    "  # Iterate alphas range and batch computation for speed, memory efficiency, and scaling to larger m_steps.\n",
    "  for alpha in tf.range(0, len(alphas), batch_size):\n",
    "    from_ = alpha\n",
    "    to = tf.minimum(from_ + batch_size, len(alphas))\n",
    "    alpha_batch = alphas[from_:to]\n",
    "\n",
    "    gradient_batch = one_batch(baseline, image, alpha_batch, target_class_idx)\n",
    "    gradient_batches.append(gradient_batch)\n",
    "\n",
    "  # Concatenate path gradients together row-wise into single tensor.\n",
    "  total_gradients = tf.concat(gradient_batches, axis=0)\n",
    "\n",
    "  # Integral approximation through averaging gradients.\n",
    "  avg_gradients = integral_approximation(gradients=total_gradients)\n",
    "\n",
    "  # Scale integrated gradients with respect to input.\n",
    "  integrated_gradients = (image - baseline) * avg_gradients\n",
    "\n",
    "  return integrated_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a62546",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def one_batch(baseline, image, alpha_batch, target_class_idx):\n",
    "    # Generate interpolated inputs between baseline and input.\n",
    "    interpolated_path_input_batch = interpolate_images(baseline=baseline,\n",
    "                                                       image=image,\n",
    "                                                       alphas=alpha_batch)\n",
    "\n",
    "    # Compute gradients between model outputs and interpolated inputs.\n",
    "    gradient_batch = compute_gradients(images=interpolated_path_input_batch,\n",
    "                                       target_class_idx=target_class_idx)\n",
    "    return gradient_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6c06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = tf.zeros(shape=(299,299,3))\n",
    "plt.imshow(baseline)\n",
    "plt.title(\"Baseline\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46748852",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_attributions = integrated_gradients(baseline=baseline,\n",
    "                                       image=adv_x[0],\n",
    "                                       target_class_idx=48,\n",
    "                                       m_steps=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e8cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ig_attributions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a223d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_attributions(baseline,\n",
    "                          image,\n",
    "                          target_class_idx,\n",
    "                          m_steps=50,\n",
    "                          cmap=None,\n",
    "                          overlay_alpha=0.4):\n",
    "\n",
    "  attributions = integrated_gradients(baseline=baseline,\n",
    "                                      image=image,\n",
    "                                      target_class_idx=target_class_idx,\n",
    "                                      m_steps=m_steps)\n",
    "\n",
    "  # Sum of the attributions across color channels for visualization.\n",
    "  # The attribution mask shape is a grayscale image with height and width\n",
    "  # equal to the original image.\n",
    "  attribution_mask = tf.reduce_sum(tf.math.abs(attributions), axis=-1)\n",
    "\n",
    "  fig, axs = plt.subplots(nrows=2, ncols=2, squeeze=False, figsize=(8, 8))\n",
    "\n",
    "  axs[0, 0].set_title('Baseline image')\n",
    "  axs[0, 0].imshow(baseline)\n",
    "  axs[0, 0].axis('off')\n",
    "\n",
    "  axs[0, 1].set_title('Original image')\n",
    "  axs[0, 1].imshow(image* 0.5 + 0.5)\n",
    "  axs[0, 1].axis('off')\n",
    "\n",
    "  axs[1, 0].set_title('Attribution mask')\n",
    "  axs[1, 0].imshow(attribution_mask, cmap=cmap)\n",
    "  axs[1, 0].axis('off')\n",
    "\n",
    "  axs[1, 1].set_title('Overlay')\n",
    "  axs[1, 1].imshow(attribution_mask * 0.5 + 0.5, cmap=cmap)\n",
    "  axs[1, 1].imshow(image * 0.5 + 0.5, alpha=overlay_alpha)\n",
    "  axs[1, 1].axis('off')\n",
    "\n",
    "  plt.tight_layout()\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f0ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_attribution_mask(baseline,\n",
    "                          image,\n",
    "                          target_class_idx,\n",
    "                          m_steps=50,):\n",
    "\n",
    "  attributions = integrated_gradients(baseline=baseline,\n",
    "                                      image=image,\n",
    "                                      target_class_idx=target_class_idx,\n",
    "                                      m_steps=m_steps)\n",
    "\n",
    "  # Sum of the attributions across color channels for visualization.\n",
    "  # The attribution mask shape is a grayscale image with height and width\n",
    "  # equal to the original image.\n",
    "  attribution_mask = tf.reduce_sum(tf.math.abs(attributions), axis=-1)\n",
    "  return attribution_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f599521",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_img_attributions(image=adv_x[0],\n",
    "                          baseline=baseline,\n",
    "                          target_class_idx=48,\n",
    "                          m_steps=240,\n",
    "                          cmap=plt.cm.inferno,\n",
    "                          overlay_alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(image[0] * 0.5 + 0.5)\n",
    "_, image_class, class_confidance = get_imagenet_label(model.predict(image))\n",
    "plt.title('Original Image\\n{} : {:.2f}% Confidance'.format(image_class, class_confidance*100))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "heatmap_original = make_gradcam_heatmap(img_array=image, model=model, last_conv_layer_name='conv_7b', pred_index=41)\n",
    "plt.imshow(heatmap_original * 0.5 + 0.5)\n",
    "plt.title(\"Heatmap\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(save_and_display_gradcam(image, heatmap_original))\n",
    "plt.title(\"Grad-CAM Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(image[0] * 0.5 + 0.5)\n",
    "_, image_class, class_confidance = get_imagenet_label(model.predict(image))\n",
    "plt.title('Original Image\\n{} : {:.2f}% Confidance'.format(image_class, class_confidance*100))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "attribution_mask = generate_attribution_mask(image=image[0], baseline=baseline, target_class_idx=41, m_steps=240,)\n",
    "plt.imshow(attribution_mask * 0.5 + 0.5)\n",
    "plt.title('Attribution Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(attribution_mask * 0.5 + 0.5, cmap=plt.cm.inferno)\n",
    "plt.imshow(image[0] * 0.5 + 0.5, alpha=0.4, cmap=plt.cm.inferno)\n",
    "plt.title(\"Original + Attribution Mask\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77df4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(adv_x[0] * 0.5 + 0.5)\n",
    "_, image_class, class_confidance = get_imagenet_label(model.predict(adv_x))\n",
    "plt.title('Adversary (epsilon = 0.01)\\n{} : {:.2f}% Confidance'.format(image_class, class_confidance*100))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "heatmap = make_gradcam_heatmap(img_array=adv_x, model=model, last_conv_layer_name='conv_7b', pred_index=48)\n",
    "plt.imshow(heatmap * 0.5 + 0.5)\n",
    "plt.title(\"Heatmap\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(save_and_display_gradcam(adv_x, heatmap))\n",
    "plt.title(\"Grad-CAM Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(adv_x[0] * 0.5 + 0.5)\n",
    "_, image_class, class_confidance = get_imagenet_label(model.predict(adv_x))\n",
    "plt.title('Adversary (epsilon = 0.01)\\n{} : {:.2f}% Confidance'.format(image_class, class_confidance*100))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "attribution_mask = generate_attribution_mask(image=adv_x[0], baseline=baseline, target_class_idx=48, m_steps=240,)\n",
    "plt.imshow(attribution_mask * 0.5 + 0.5)\n",
    "plt.title('Attribution Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(attribution_mask * 0.5 + 0.5, cmap=plt.cm.inferno)\n",
    "plt.imshow(adv_x[0] * 0.5 + 0.5, alpha=0.4, cmap=plt.cm.inferno)\n",
    "plt.title(\"Adversary + Attribution Mask\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b084a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_img_attributions(image=image[0],\n",
    "                          baseline=baseline,\n",
    "                          target_class_idx=41,\n",
    "                          m_steps=240,\n",
    "                          cmap=plt.cm.inferno,\n",
    "                          overlay_alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32235782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
