{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmC7wdQK9vY-",
        "outputId": "60fb32ac-6dd0-41b3-a49b-e1f065eaad1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# --- Settings ---\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 30\n",
        "LATENT_DIM = 2\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/Colab Notebooks/DL_2025/8/'\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/reconstructions', exist_ok=True)\n",
        "\n",
        "# --- Load data ---\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# --- Encoder ---\n",
        "encoder_inputs = layers.Input(shape=(32,32,3))\n",
        "x = layers.Conv2D(32,3,activation='relu', padding='same', strides=2)(encoder_inputs)\n",
        "x = layers.Conv2D(64,3,activation='relu', padding='same', strides=2)(x)\n",
        "x = layers.Conv2D(128,3,activation='relu', padding='same', strides=2)(x)\n",
        "x = layers.Flatten()(x)\n",
        "latent = layers.Dense(LATENT_DIM, name='latent2d')(x)\n",
        "encoder = models.Model(encoder_inputs, latent, name='encoder')\n",
        "\n",
        "# --- Decoder ---\n",
        "latent_inputs = layers.Input(shape=(LATENT_DIM,))\n",
        "x = layers.Dense(4*4*128, activation='relu')(latent_inputs)\n",
        "x = layers.Reshape((4,4,128))(x)\n",
        "x = layers.Conv2DTranspose(128,3,activation='relu', padding='same', strides=2)(x)\n",
        "x = layers.Conv2DTranspose(64,3,activation='relu', padding='same', strides=2)(x)\n",
        "x = layers.Conv2DTranspose(32,3,activation='relu', padding='same', strides=2)(x)\n",
        "decoder_outputs = layers.Conv2D(3,3,activation='sigmoid', padding='same')(x)\n",
        "decoder = models.Model(latent_inputs, decoder_outputs, name='decoder')\n",
        "\n",
        "# --- Autoencoder ---\n",
        "ae_input = encoder_inputs\n",
        "ae_output = decoder(encoder(ae_input))\n",
        "autoencoder = models.Model(ae_input, ae_output, name='autoencoder')\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# --- Train ---\n",
        "history = autoencoder.fit(\n",
        "    x_train, x_train,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    validation_data=(x_test, x_test)\n",
        ")\n",
        "pd.DataFrame(history.history).to_csv(f'{OUTPUT_DIR}/loss_history.csv', index=False)\n",
        "\n",
        "# --- Save sample reconstructions ---\n",
        "n = 10\n",
        "idxs = np.random.choice(len(x_test), n)\n",
        "recons = autoencoder.predict(x_test[idxs])\n",
        "fig, axes = plt.subplots(2, n, figsize=(20,4))\n",
        "for i in range(n):\n",
        "    axes[0,i].imshow(x_test[idxs[i]])\n",
        "    axes[0,i].axis('off')\n",
        "    axes[1,i].imshow(recons[i])\n",
        "    axes[1,i].axis('off')\n",
        "plt.savefig(f'{OUTPUT_DIR}/reconstructions/sample_recons.png')\n",
        "\n",
        "# --- Encode to 2D features ---\n",
        "features = encoder.predict(np.vstack([x_train, x_test]))\n",
        "labels = np.concatenate([y_train, y_test]).reshape(-1)\n",
        "df = pd.DataFrame(features, columns=['dim1','dim2'])\n",
        "df['label'] = labels\n",
        "df.to_csv(f'{OUTPUT_DIR}/latent_2d.csv', index=False)\n",
        "\n",
        "# --- Plot latent space ---\n",
        "plt.figure(figsize=(8,6))\n",
        "scatter = plt.scatter(df['dim1'], df['dim2'], c=df['label'], cmap='tab10', s=5)\n",
        "plt.colorbar(scatter, ticks=range(10))\n",
        "plt.title('2D latent space of CIFARâ€‘10')\n",
        "plt.savefig(f'{OUTPUT_DIR}/latent2d_plot.png')\n",
        "# plt.close()\n"
      ],
      "metadata": {
        "id": "Saw_BusB9_xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.image import resize"
      ],
      "metadata": {
        "id": "9AW3UdOg_V6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Resize images to match ResNet input ---\n",
        "x_all = np.vstack([x_train, x_test])\n",
        "y_all = np.vstack([y_train, y_test]).reshape(-1)"
      ],
      "metadata": {
        "id": "GeM_zG-ZEg-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_in_batches(images, target_size=(224, 224), batch_size=100):\n",
        "    resized_images = []\n",
        "    for i in range(0, len(images), batch_size):\n",
        "        batch = images[i:i+batch_size]\n",
        "        resized_batch = tf.image.resize(batch, target_size).numpy()\n",
        "        resized_images.append(resized_batch)\n",
        "    return np.vstack(resized_images)\n",
        "\n",
        "# Resize all images (train + test) in smaller batches\n",
        "x_all_resized = resize_in_batches(x_all, target_size=(224, 224))\n",
        "x_all_resized = preprocess_input(x_all_resized)\n"
      ],
      "metadata": {
        "id": "gzNbX68JEaHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load ResNet50 without top classifier ---\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "resnet_model = Model(inputs=base_model.input, outputs=base_model.output)\n",
        "\n",
        "# --- Extract features (shape: N, 7,7,2048) -> flatten ---\n",
        "features_resnet = resnet_model.predict(x_all_resized, batch_size=64, verbose=1)\n",
        "features_resnet = features_resnet.reshape(features_resnet.shape[0], -1)  # (N, 100352)"
      ],
      "metadata": {
        "id": "E0du9HsWD2tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PCA Reduction to 50 dims, then t-SNE to 2D ---\n",
        "print(\"Running PCA...\")\n",
        "pca = PCA(n_components=50)\n",
        "resnet_pca50 = pca.fit_transform(features_resnet)\n",
        "\n",
        "print(\"Running t-SNE...\")\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30, init='pca', learning_rate='auto')\n",
        "resnet_tsne2d = tsne.fit_transform(resnet_pca50)\n",
        "\n",
        "# --- Save features ---\n",
        "df_resnet = pd.DataFrame(resnet_tsne2d, columns=['dim1', 'dim2'])\n",
        "df_resnet['label'] = y_all\n",
        "df_resnet.to_csv(f'{OUTPUT_DIR}/resnet50_tsne2d.csv', index=False)"
      ],
      "metadata": {
        "id": "UaIB-G0KD5qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Plot AE vs ResNet+tSNE side by side ---\n",
        "fig, axs = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Autoencoder plot\n",
        "axs[0].scatter(df['dim1'], df['dim2'], c=df['label'], cmap='tab10', s=5)\n",
        "axs[0].set_title('Autoencoder 2D Latent Space')\n",
        "\n",
        "# ResNet t-SNE plot\n",
        "axs[1].scatter(df_resnet['dim1'], df_resnet['dim2'], c=df_resnet['label'], cmap='tab10', s=5)\n",
        "axs[1].set_title('ResNet50 Features + PCA + t-SNE')\n",
        "\n",
        "for ax in axs:\n",
        "    ax.set_xlabel('dim1')\n",
        "    ax.set_ylabel('dim2')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{OUTPUT_DIR}/ae_vs_resnet_tsne.png')\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "ULgPXth2D83z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}